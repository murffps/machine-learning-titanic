{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONOd6JeWVjOYhc+xOeHorx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murffps/machine-learning-titanic/blob/main/MLBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "matplotlib\n",
        "pandas\n",
        "sklearn \n",
        "yellowbrick\n",
        "xlrd"
      ],
      "metadata": {
        "id": "17olroObDUtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip "
      ],
      "metadata": {
        "id": "qTFYNUwKDXzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFo1kYBAnjFw"
      },
      "source": [
        "\n",
        "\n",
        "# source [https://www.oreilly.com/library/view/machine-learning-pocket/9781492047537/]\n",
        "# (Type of ML Prediction) Classification Supervised Learning : \n",
        "# Classify whether an individual survies the Titanic ship catastrophe \n",
        "#   based on individual and trip characteristics. (transform features into a label)\n",
        "# Predict if they will (did) survive based on certain characteristic\n",
        "# Would they survive based on ...\n",
        "\n",
        "# import tools and libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import (ensemble, preprocessing,tree)\n",
        "from sklearn.metrics import (auc, confusion_matrix, roc_auc_score, roc_curve)\n",
        "from sklearn.model_selection import (train_test_split, StratifiedKFold)\n",
        "from yellowbrick.classifier import (ConfusionMatrix, ROCAUC)\n",
        "from yellowbrick.model_selection import (LearningCurve)\n",
        "import ydata_profiling\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# GATHER DATA\n",
        "url = (\"https://biostat.app.vumc.org/wiki/pub/Main/DataSets/titanic3.xls\")\n",
        "df = pd.read_excel(url)\n",
        "orig_df = df\n",
        "\n",
        "# CLEAN DATA - Standardize, Outliers(check min/max), Missing Data(check for NaN)\n",
        "ydata_profiling.ProfileReport(df)\n",
        "df.shape\n",
        "profile = ProfileReport(df, title=\"data set\", html={'style' : {'full_width':True}})\n",
        "profile.to_file(output_file=\"file.html\")\n",
        "\n",
        "\n",
        "# profile\n",
        "df.describe().iloc[:, :2]\n",
        "\n",
        "# missing data \n",
        "# conclusions: age (interpolate values), cabin, boat, body all going to be dropped -LEAKY - \n",
        "df.isnull().sum()\n",
        "\n",
        "df.isnull().mean() * 100\n",
        "\n",
        "# inspect some specific data\n",
        "# decide on strategy to replace or deal with missing data  \n",
        "# a. Use S the most common to  \n",
        "# b. drop them -- One possible strategy is to drop columns with no variance or signal or perfect or very high positive or negative correlation\n",
        "# c. use pandas to create dummy columns with all 0s \n",
        "df.sex.value_counts(dropna=False)\n",
        "\n",
        "df.embarked.value_counts(dropna=False)\n",
        "\n",
        "## CREATE FEATURES \n",
        "name = df.name\n",
        "name.head(3)\n",
        "\n",
        "df = df.drop(\n",
        "    columns=[\n",
        "        \"name\",\n",
        "        \"ticket\",\n",
        "        \"home.dest\",\n",
        "        \"boat\",\n",
        "        \"body\",\n",
        "        \"cabin\"\n",
        "    ])\n",
        "\n",
        "df = pd.get_dummies(df)\n",
        "df.columns\n",
        "\n",
        "df = df.drop(columns=\"sex_male\")\n",
        "# OR df = pd.get_dummies(df, drop_first=True)\n",
        "df.columns\n",
        "\n",
        "y = df.survived\n",
        "X = df.drop(columns=\"survived\")\n",
        "\n",
        "## SAMPLE DATA - pull out 30% \n",
        "# X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "#not working NameError: name 'model_selection' is not defined\n",
        "\n",
        "# Impute missing values for age on training set "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View HTML file \n",
        "import IPython\n",
        "IPython.display.HTML(filename='/content/file.html')"
      ],
      "metadata": {
        "id": "wbTE3WmIKNBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9u6dN7zBuk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}